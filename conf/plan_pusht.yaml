defaults:
  - _self_
  - override hydra/launcher: submitit_slurm

hydra:
  run:
    dir: plan_outputs/${now:%Y%m%d%H%M%S}_${replace_slash:${model_name}}_gH${goal_H}
  sweep:
    dir: plan_outputs/${now:%Y%m%d%H%M%S}_${replace_slash:${model_name}}_gH${goal_H}
    subdir: ${hydra.job.num}
  launcher:
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    nodes: 1
    tasks_per_node: 1
    cpus_per_task: 16
    mem_gb: 256
    gres: "gpu:h100:1"
    qos: "explore"
    timeout_min: 720
    setup: ["export DEBUGVAR=$(scontrol show hostnames $SLURM_JOB_NODELIST)",
            export MASTER_ADDR="$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
            "export MASTER_PORT=$(for port in $(shuf -i 30000-65500 -n 20); do if [[ $(netstat -tupln 2>&1 | grep $port | wc -l) -eq 0 ]] ; then echo $port; break; fi; done;)",]

# model to load for planning
ckpt_base_path: /home/coder/volume/pretrained
model_name: pusht
model_epoch: latest

# use_initnet: True
# init_ckpt_path: /home/coder/volume/initnet_pusht.pth

# ckpt_base_path: /home/coder/volume/checkpoints  # put absolute path here. Checkpoints will be loaded from ${ckpt_base_path}/outputs
# model_name: pgd.full #pusht.dagger.6000
# model_epoch: 1

seed: 99
n_evals: 50
goal_source: 'dset'
goal_H: 5 
n_plot_samples: 10

debug_dset_init: False

objective:
  _target_: planning.objectives.create_objective_fn
  alpha: 1
  base: 2
  mode: all

# open-loop
planner:
  _target_: planning.gd.GDPlanner
  horizon: 5
  action_noise: 0.003
  sample_type: 'randn' # 'zero', 'randn', 'initnet'
  lr: 3e-1
  opt_steps: 300
  eval_every: 10
  optimizer_type: "adam"
  rollout_type: "custom"
  name: gd

# closed-loop
# planner:
#   _target_: planning.mpc.MPCPlanner
#   max_iter: null
#   n_taken_actions: 1
#   sub_planner:
#     action_noise: 0.003
#     eval_every: 80
#     horizon: 5
#     lr: 0.2
#     opt_steps: 100
#     optimizer_type: adam
#     rollout_type: custom
#     sample_type: randn
#     target: planning.gd.GDPlanner
#   name: mpc_gd
